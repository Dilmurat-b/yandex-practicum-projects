{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2ddd30-2413-4749-a22a-03233bb08774",
   "metadata": {},
   "source": [
    "# Adam optimization algorithm [GPU]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82940d0b",
   "metadata": {},
   "source": [
    "In this task it was necessary to build and train a neural network on a dataset of clothing items using Adam optimizer. It is necessary that the accuracy value on the test sample should be at least 87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07489a0-6355-4a83-91dd-f04a9a3f7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    ZeroPadding2D,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ef448a-943a-45e3-bd23-84a57a2958a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(-1, 28, 28, 1) / 255.\n",
    "    return features_train, target_train\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), input_shape=input_shape))\n",
    "    model.add(Conv2D(10, (6, 6), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=(1, 1)))\n",
    "    model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "    model.add(Conv2D(20, (6, 6), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=(1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), \n",
    "        loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=2000, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train,\n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "   \n",
    "               verbose=1, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdadcb-fd99-46ca-a702-2e09fd21b7a8",
   "metadata": {},
   "source": [
    "**Neural Network Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97451ab-feb7-41df-a919-bc498bfa04aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ zero_padding2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,220</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ zero_padding2d (\u001b[38;5;33mZeroPadding2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m370\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │            \u001b[38;5;34m40\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ zero_padding2d_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │         \u001b[38;5;34m7,220\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │            \u001b[38;5;34m80\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m4,096,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,109,352</span> (15.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,109,352\u001b[0m (15.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,109,292</span> (15.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,109,292\u001b[0m (15.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> (240.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m60\u001b[0m (240.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model(input_shape=(28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebff39f-fd82-407c-87e5-7c345c987f2c",
   "metadata": {},
   "source": [
    "**Result of output model**\n",
    "```\n",
    "Train on 60000 samples, validate on 10000 samples\n",
    "Epoch 1/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1:14 - loss: 4.3144 - acc: 0.0890\n",
    " 6000/60000 [==>...........................] - ETA: 23s - loss: 28.2875 - acc: 0.3428\n",
    "10000/60000 [====>.........................] - ETA: 13s - loss: 28.3149 - acc: 0.3796\n",
    "14000/60000 [======>.......................] - ETA: 9s - loss: 23.5178 - acc: 0.4499 \n",
    "18000/60000 [========>.....................] - ETA: 6s - loss: 19.7459 - acc: 0.4976\n",
    "22000/60000 [==========>...................] - ETA: 5s - loss: 16.8175 - acc: 0.5275\n",
    "26000/60000 [============>.................] - ETA: 3s - loss: 14.5896 - acc: 0.5447\n",
    "30000/60000 [==============>...............] - ETA: 3s - loss: 12.8652 - acc: 0.5570\n",
    "34000/60000 [================>.............] - ETA: 2s - loss: 11.5210 - acc: 0.5656\n",
    "38000/60000 [==================>...........] - ETA: 1s - loss: 10.4484 - acc: 0.5722\n",
    "42000/60000 [====================>.........] - ETA: 1s - loss: 9.5754 - acc: 0.5776 \n",
    "46000/60000 [======================>.......] - ETA: 1s - loss: 8.8424 - acc: 0.5829\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 8.2243 - acc: 0.5893\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 7.6874 - acc: 0.5966\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 7.2282 - acc: 0.6038\n",
    "60000/60000 [==============================] - 4s 65us/step - loss: 7.0317 - acc: 0.6066 - val_loss: 13.9853 - val_acc: 0.2440\n",
    "Epoch 2/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.9709 - acc: 0.7070\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.9966 - acc: 0.6900\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.9967 - acc: 0.6981\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.9697 - acc: 0.6942\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.9381 - acc: 0.7008\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.9256 - acc: 0.7039\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.9021 - acc: 0.7053\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.8888 - acc: 0.7071\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.8740 - acc: 0.7097\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.8593 - acc: 0.7121\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.8452 - acc: 0.7152\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.8335 - acc: 0.7173\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.8233 - acc: 0.7189\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.8152 - acc: 0.7210\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.8062 - acc: 0.7235\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.8011 - acc: 0.7247 - val_loss: 23.5452 - val_acc: 0.2165\n",
    "Epoch 3/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.6325 - acc: 0.7410\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.6398 - acc: 0.7528\n",
    "10000/60000 [====>.........................] - ETA: 1s - loss: 0.6519 - acc: 0.7589\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.6434 - acc: 0.7631\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.6402 - acc: 0.7643\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.6405 - acc: 0.7653\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.6368 - acc: 0.7663\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.6357 - acc: 0.7678\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.6339 - acc: 0.7682\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.6362 - acc: 0.7686\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.6348 - acc: 0.7700\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.6316 - acc: 0.7703\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.6292 - acc: 0.7711\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.6269 - acc: 0.7721\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.6260 - acc: 0.7726\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.6250 - acc: 0.7731 - val_loss: 37.7461 - val_acc: 0.2284\n",
    "Epoch 4/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.5971 - acc: 0.7690\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.5697 - acc: 0.7835\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.5784 - acc: 0.7806\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.5931 - acc: 0.7790\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.5951 - acc: 0.7783\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.5903 - acc: 0.7805\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.5843 - acc: 0.7812\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.5850 - acc: 0.7814\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.5826 - acc: 0.7826\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.5838 - acc: 0.7825\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.5820 - acc: 0.7838\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.5772 - acc: 0.7857\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.5763 - acc: 0.7864\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.5748 - acc: 0.7865\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.5730 - acc: 0.7867\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.5746 - acc: 0.7866 - val_loss: 49.9937 - val_acc: 0.1921\n",
    "Epoch 5/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.5370 - acc: 0.7980\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.5384 - acc: 0.7963\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.5452 - acc: 0.7937\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.5452 - acc: 0.7944\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.5461 - acc: 0.7937\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.5426 - acc: 0.7955\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.5412 - acc: 0.7962\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.5361 - acc: 0.7977\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.5311 - acc: 0.7999\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.5338 - acc: 0.7997\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.5330 - acc: 0.8001\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.5319 - acc: 0.8010\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.5301 - acc: 0.8018\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.5310 - acc: 0.8024\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.5286 - acc: 0.8034\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.5285 - acc: 0.8034 - val_loss: 53.6421 - val_acc: 0.2022\n",
    "Epoch 6/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4995 - acc: 0.8190\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.5092 - acc: 0.8133\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.5101 - acc: 0.8085\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.5141 - acc: 0.8095\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.5101 - acc: 0.8097\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.5018 - acc: 0.8126\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.5037 - acc: 0.8113\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.5013 - acc: 0.8122\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.5009 - acc: 0.8124\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.5048 - acc: 0.8122\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.5057 - acc: 0.8122\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.5065 - acc: 0.8126\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.5066 - acc: 0.8128\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.5065 - acc: 0.8137\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.8133\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.5053 - acc: 0.8134 - val_loss: 52.1498 - val_acc: 0.1833\n",
    "Epoch 7/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.5013 - acc: 0.8170\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4829 - acc: 0.8212\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.4931 - acc: 0.8206\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.4877 - acc: 0.8199\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.4923 - acc: 0.8176\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.4888 - acc: 0.8180\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.4835 - acc: 0.8201\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.4818 - acc: 0.8213\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.4799 - acc: 0.8225\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4807 - acc: 0.8225\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.4790 - acc: 0.8230\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.4796 - acc: 0.8229\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.4793 - acc: 0.8233\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.4797 - acc: 0.8231\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.8229\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.4781 - acc: 0.8229 - val_loss: 46.6506 - val_acc: 0.2175\n",
    "Epoch 8/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4599 - acc: 0.8280\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4644 - acc: 0.8283\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.4587 - acc: 0.8296\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.4606 - acc: 0.8286\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.4590 - acc: 0.8299\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.4572 - acc: 0.8307\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.4527 - acc: 0.8320\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.4549 - acc: 0.8318\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.4533 - acc: 0.8324\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4523 - acc: 0.8323\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.4527 - acc: 0.8323\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.4513 - acc: 0.8330\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.4529 - acc: 0.8324\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.4519 - acc: 0.8326\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8323\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.4544 - acc: 0.8322 - val_loss: 39.0215 - val_acc: 0.2279\n",
    "Epoch 9/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4601 - acc: 0.8380\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4572 - acc: 0.8380\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.4511 - acc: 0.8353\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.4516 - acc: 0.8356\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.4410 - acc: 0.8395\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.4407 - acc: 0.8382\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.4429 - acc: 0.8359\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.4447 - acc: 0.8353\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.4463 - acc: 0.8356\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4435 - acc: 0.8368\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.4435 - acc: 0.8363\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.4412 - acc: 0.8370\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.4400 - acc: 0.8378\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.4392 - acc: 0.8383\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8385\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.4377 - acc: 0.8386 - val_loss: 32.9108 - val_acc: 0.2306\n",
    "Epoch 10/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4423 - acc: 0.8330\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4465 - acc: 0.8367\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.4388 - acc: 0.8374\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.4370 - acc: 0.8361\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.4288 - acc: 0.8397\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.4306 - acc: 0.8388\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.4290 - acc: 0.8404\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.4281 - acc: 0.8415\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.4284 - acc: 0.8420\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4281 - acc: 0.8419\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.4293 - acc: 0.8409\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.4303 - acc: 0.8406\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.4314 - acc: 0.8409\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.4316 - acc: 0.8413\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.4304 - acc: 0.8419\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.4315 - acc: 0.8417 - val_loss: 22.8943 - val_acc: 0.2628\n",
    "Epoch 11/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3972 - acc: 0.8550\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4093 - acc: 0.8492\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.4116 - acc: 0.8475\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.4164 - acc: 0.8439\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.4183 - acc: 0.8434\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.4207 - acc: 0.8440\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.4189 - acc: 0.8446\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.4182 - acc: 0.8445\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.4168 - acc: 0.8451\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4155 - acc: 0.8459\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.4161 - acc: 0.8462\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.4168 - acc: 0.8464\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.4152 - acc: 0.8468\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.4147 - acc: 0.8471\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.4136 - acc: 0.8471\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.4132 - acc: 0.8471 - val_loss: 10.3013 - val_acc: 0.4439\n",
    "Epoch 12/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4004 - acc: 0.8495\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4270 - acc: 0.8457\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.4073 - acc: 0.8517\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.4073 - acc: 0.8489\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.4046 - acc: 0.8506\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.4037 - acc: 0.8506\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.4020 - acc: 0.8517\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.4052 - acc: 0.8505\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.4053 - acc: 0.8507\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4046 - acc: 0.8512\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.4058 - acc: 0.8511\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.4054 - acc: 0.8513\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.4047 - acc: 0.8511\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.4047 - acc: 0.8514\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.4052 - acc: 0.8516\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.4035 - acc: 0.8521 - val_loss: 10.0824 - val_acc: 0.4645\n",
    "Epoch 13/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4035 - acc: 0.8460\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3991 - acc: 0.8520\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3969 - acc: 0.8524\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3862 - acc: 0.8560\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3857 - acc: 0.8576\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3844 - acc: 0.8583\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3848 - acc: 0.8579\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3859 - acc: 0.8574\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3825 - acc: 0.8583\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3849 - acc: 0.8572\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3859 - acc: 0.8576\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3874 - acc: 0.8570\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3905 - acc: 0.8557\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3903 - acc: 0.8552\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3905 - acc: 0.8552\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3901 - acc: 0.8556 - val_loss: 3.1448 - val_acc: 0.6821\n",
    "Epoch 14/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3846 - acc: 0.8605\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3810 - acc: 0.8592\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3795 - acc: 0.8604\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3843 - acc: 0.8579\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3875 - acc: 0.8575\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3849 - acc: 0.8581\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3856 - acc: 0.8581\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3876 - acc: 0.8573\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3880 - acc: 0.8577\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3892 - acc: 0.8572\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3874 - acc: 0.8578\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3862 - acc: 0.8582\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3856 - acc: 0.8584\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3863 - acc: 0.8575\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8578\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3848 - acc: 0.8577 - val_loss: 3.2476 - val_acc: 0.6964\n",
    "Epoch 15/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.4079 - acc: 0.8515\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3873 - acc: 0.8612\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3794 - acc: 0.8629\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3802 - acc: 0.8613\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3820 - acc: 0.8598\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3852 - acc: 0.8601\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3832 - acc: 0.8603\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3833 - acc: 0.8596\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3858 - acc: 0.8582\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3830 - acc: 0.8600\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3827 - acc: 0.8606\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3807 - acc: 0.8608\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3813 - acc: 0.8598\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3823 - acc: 0.8590\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3814 - acc: 0.8593\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3819 - acc: 0.8591 - val_loss: 1.4992 - val_acc: 0.7655\n",
    "Epoch 16/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3829 - acc: 0.8570\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3758 - acc: 0.8612\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3754 - acc: 0.8624\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3826 - acc: 0.8585\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3826 - acc: 0.8581\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3810 - acc: 0.8597\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3804 - acc: 0.8598\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3793 - acc: 0.8600\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3797 - acc: 0.8596\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3778 - acc: 0.8604\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3744 - acc: 0.8617\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3747 - acc: 0.8622\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3739 - acc: 0.8628\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3748 - acc: 0.8624\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8623\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3742 - acc: 0.8625 - val_loss: 0.8692 - val_acc: 0.8057\n",
    "Epoch 17/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3754 - acc: 0.8560\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3627 - acc: 0.8618\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3657 - acc: 0.8625\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3594 - acc: 0.8650\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3594 - acc: 0.8664\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3566 - acc: 0.8666\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3555 - acc: 0.8664\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3549 - acc: 0.8663\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3580 - acc: 0.8657\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3581 - acc: 0.8659\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3590 - acc: 0.8657\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3595 - acc: 0.8663\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3601 - acc: 0.8659\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3596 - acc: 0.8659\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3598 - acc: 0.8659\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3585 - acc: 0.8663 - val_loss: 0.7790 - val_acc: 0.8257\n",
    "Epoch 18/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3514 - acc: 0.8675\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3534 - acc: 0.8722\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3603 - acc: 0.8717\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3626 - acc: 0.8701\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3643 - acc: 0.8696\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3581 - acc: 0.8714\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3578 - acc: 0.8714\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3556 - acc: 0.8714\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3566 - acc: 0.8702\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3577 - acc: 0.8695\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3579 - acc: 0.8694\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3607 - acc: 0.8684\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3614 - acc: 0.8688\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3583 - acc: 0.8693\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3561 - acc: 0.8697\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3576 - acc: 0.8697 - val_loss: 0.6770 - val_acc: 0.8528\n",
    "Epoch 19/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3460 - acc: 0.8740\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3513 - acc: 0.8708\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3454 - acc: 0.8736\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3391 - acc: 0.8723\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3421 - acc: 0.8712\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3444 - acc: 0.8722\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3462 - acc: 0.8717\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3463 - acc: 0.8717\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3474 - acc: 0.8719\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3460 - acc: 0.8729\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3472 - acc: 0.8728\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3483 - acc: 0.8725\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3482 - acc: 0.8723\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3490 - acc: 0.8724\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8721\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3488 - acc: 0.8722 - val_loss: 0.5554 - val_acc: 0.8586\n",
    "Epoch 20/20\n",
    "\n",
    " 2000/60000 [>.............................] - ETA: 1s - loss: 0.3137 - acc: 0.8815\n",
    " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.3425 - acc: 0.8772\n",
    "10000/60000 [====>.........................] - ETA: 0s - loss: 0.3352 - acc: 0.8769\n",
    "14000/60000 [======>.......................] - ETA: 0s - loss: 0.3328 - acc: 0.8771\n",
    "18000/60000 [========>.....................] - ETA: 0s - loss: 0.3390 - acc: 0.8751\n",
    "22000/60000 [==========>...................] - ETA: 0s - loss: 0.3408 - acc: 0.8743\n",
    "26000/60000 [============>.................] - ETA: 0s - loss: 0.3393 - acc: 0.8747\n",
    "30000/60000 [==============>...............] - ETA: 0s - loss: 0.3384 - acc: 0.8747\n",
    "34000/60000 [================>.............] - ETA: 0s - loss: 0.3373 - acc: 0.8748\n",
    "38000/60000 [==================>...........] - ETA: 0s - loss: 0.3390 - acc: 0.8745\n",
    "42000/60000 [====================>.........] - ETA: 0s - loss: 0.3402 - acc: 0.8749\n",
    "46000/60000 [======================>.......] - ETA: 0s - loss: 0.3412 - acc: 0.8743\n",
    "50000/60000 [========================>.....] - ETA: 0s - loss: 0.3410 - acc: 0.8740\n",
    "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3428 - acc: 0.8735\n",
    "58000/60000 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.8736\n",
    "60000/60000 [==============================] - 1s 21us/step - loss: 0.3429 - acc: 0.8733 - val_loss: 0.3840 - val_acc: 0.8789\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e87131-20e1-4257-b615-35bc49e813c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
